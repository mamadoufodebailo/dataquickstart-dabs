{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6dfe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d790b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_target = spark.conf.get(\"display_target\")\n",
    "catalog = spark.conf.get(\"catalog_name\")\n",
    "raw_data_path = spark.conf.get(\"raw_data_path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50453c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table\n",
    "def raw_data():\n",
    "    return (spark.readStream\n",
    "    .format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"cloudFiles.schemaEvolutionMode\", \"rescue\")\n",
    "    .option(\"cloudFiles.inferColumnTypes\", \"true\")\n",
    "    .load(f\"{raw_data_path}\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337895ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table\n",
    "def ingest_data():\n",
    "    return spark.read.table(f\"{catalog}.default.health_silver_demo_01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af65a8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table\n",
    "def joined_data():\n",
    "    df = (dlt.read(\"ingest_data\").alias(\"s\")\n",
    "    .join(dlt.read(\"raw_data\").alias(\"u\"), \"s.station_id=u.station_id\", \"inner\")\n",
    "    .selectExpr(\"s.station_id\", \"s.name\", \"s.lat\", \"s.long\", \"s.dockcount\", \"s.landmark\", \"u._metadata\")\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda23e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dlt.table\n",
    "def aggragted_data():\n",
    "    from pyspark.sql.functions import count, sum\n",
    "\n",
    "    df = (dlt.read(\"joined_data\")\n",
    "    .groupBy(\"landmark\")\n",
    "    .agg(count(\"landmark\").alias(\"count\"), sum(\"dockcount\").alias(\"total\"))\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
